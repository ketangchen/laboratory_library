args:
  dtype:
  - Tensor
  - Tensor
  - Tensor
  is_pos:
  - true
  - false
  - false
  name:
  - self
  - other
  - out
  required:
  - true
  - true
  - true
name: torch.true_divide
package: torch
pass_rate: 100
rules:
- - cot: 'The error is triggered because the size of tensor `a` (4) does not match
      the size of tensor `b` (9) at non-singleton dimension 1. To prevent this error,
      we can formulate the constraint as follows:'
    length: 1
    target:
      choosen_dtype:
        other: tensor
        out: tensor
        self: tensor
      msg: The size of tensor a (5) must match the size of tensor b (9) at non-singleton
        dimension 6
      package: torch
    txt: self.shape[1] == other.shape[1]
  - f1_score: 74.21150278293136
    overall_score: 100
    precision: 100.0
    recall: 58.99705014749264
- - cot: 'The error message indicates that we are trying to resize the ''out'' tensor,
      which is not resizable. To prevent this error, we need to ensure that the shape
      and rank of the ''out'' tensor match the shape and rank of the operation result
      (in this case, the ''self'' tensor).


      Therefore, the condition to prevent the error is:'
    length: 1
    target:
      choosen_dtype:
        other: tensor
        out: tensor
        self: tensor
      msg: Trying to resize storage that is not resizable
      package: torch
    txt: out.rank == self.rank and all(out.shape[i] == self.shape[i] for i in range(out.rank))
  - f1_score: 36.4063417498532
    overall_score: 18.57788944723618
    precision: 31.155778894472363
    recall: 43.78531073446328
- - cot: synthesized
    length: 2
    target:
      choosen_dtype:
        other: tensor
        out: tensor
        self: tensor
      msg: result type Float can't be cast to the desired output type Int
      package: torch
    txt: (dtype(self) == "float32") and (dtype(self) == dtype(out))
  - f1_score: 91.32420091324202
    overall_score: 51.66210045662101
    precision: 100.0
    recall: 84.03361344537815
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        other: tensor
        out: tensor
        self: tensor
      msg: Trying to resize storage that is not resizable
      package: torch
    txt: self.rank==other.rank and all(self.shape[i]==other.shape[i] for i in range(self.rank))
  - f1_score: 85.64814814814815
    overall_score: 54.824074074074076
    precision: 92.96482412060301
    recall: 79.39914163090128
- - cot: default
    length: 3
    target:
      choosen_dtype:
        other: Tensor
        out: Tensor
        self: Tensor
      msg: negative dimensions are not allowed
      package: torch
    txt: all(i >= 0 for i in self.shape) and all(i >= 0 for i in other.shape) and
      all(i >= 0 for i in out.shape)
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
- - cot: default
    length: 3
    target:
      choosen_dtype:
        other: Tensor
        out: Tensor
        self: Tensor
      msg: Too large tensor shape
      package: torch
    txt: self.rank <= 7 and other.rank <= 7 and out.rank <= 7
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
