{
    "All input tensors should have same dimension but got sizes: input1: torch.Size([]), input2: torch.Size([5, 2, 3, 5, 6, 5, 15]), target: torch.Size([13, 18, 12])": {
      "answers": "input1.dim == input2.dim;input1.dim==target.dim",
      "cot": "Based on given values, Error is triggered because all input tensors don't have same dimension. It expects to have same dimension among all tensors. Let's see what the args were. It seems dimensions of input1, input2, and target are not same, so input.dim, input2.dim, target.dim should be corrected. Therefore, Left : input.dim. Op : ==, and Right : input2.dim or target.dim"
    },
    "The size of tensor a (4) must match the size of tensor b (7) at non-singleton dimension 0": {
      "answers": "{arg1_name}.dim == {arg2_name}.dim and {arg_name}.shape == {arg2_name}.shape",
      "cot": "Based on given values, Error is triggered because the two tensors are not inconistent. It expects to have same dimension among all tensors. Let's see what the args were. It seems dimensions and shape of a, and b are which should be corrected. Therefore, Left : {arg_name}.dim, {arg_name}.shape Op : ==, and Right : b.dim, b.shape"
    },
    "Can not squeeze dim, expected a dimension of 1, got 8 name:": {
      "answers": "all({arg1_name}[i] < len({arg2_name}.shape) and {arg2_name}.shape[{arg1_name}[i]] == 1 for i in range(len({arg1_name})))",
      "cot": "The error is due to an invalid squeeze dimension. What the args were? The function is trying to squeeze on dimension 8 of the input tensor, but the corresponding values are not 1. Squeezing a dimension is only valid if the size of that dimension is 1. Therefore, each axis[i] in axis should be a valid dimension (i.e., < input.rank), Op : <, and Right : input.rank. Also, the size of that dimension in the input tensor should be 1. So, input[axis[i]].dim should be 1, Op : ==, and Right : 1."
    },
    "Dimension out of range (expected to be in range of [-2, 1], but got 7)": {
      "answers": "{arg2_name} >= -len({arg1_name}.shape) and {arg2_name} < len({arg1_name}.shape); all(d >= -len({arg1_name}.shape) and d < len({arg1_name}.shape) for d in {arg2_name})",
      "cot": "The error occurs because the dimension provided is out of the valid range. Let's see what the args were. It related with arg_name 'dim=7', which is out of this range. To prevent this error in the future and generate constraints that do not trigger it, we need to ensure that the \"dim\" value is always within the valid range for the given tensor. If we denote the shape of the tensor as n, the valid range for the dimension would be [-n, n-1].The constraint for the 'dim' parameter can be expressed as:"
    },
    "Exception encountered when calling layer 'max_pooling1d_28' (type MaxPooling1D).  Stride must be > 0, but got 0": {
      "answers": "all(i>0 for i in strides);strides>0",
      "cot": "The error is caused because the stride value for the layer \"max_pooling1d_28\" is not as expected. What the args were? The layer expects a stride value greater than 0, but found a stride value of 0. Therefore, Left : strides which is the stride value should be corrected. It says that cannot be 0, so Op : !=, and Right : 0. Also, it should be greater than 0, so Op : >, and Right : 0."
    },
    "Expected 2 to 3 dimensions, but got 1-dimensional tensor for argument 1 'self' (while checking arguments for adaptive_avg_pool1d)": {
      "answers": "{arg1_name}.ndims() == 2 or {arg1_name}.ndims() == 3;{arg1_name}.ndims() != 1",
      "cot": "Error is triggered because of 1-dimensional tensor. it expects to have 2 or 3 dimentions. Let's see what the args were. It seems example_key has 1 dimension, and is the problem. so the number of dimensions of example_key should be corrected, which is example_key.ndims(). Therefore, Left : example_key.ndims(). It says that expected 2 to 3, so Op : ==, and Right : 2 or 3. Also, It implies that dimension cannot be 1, so Op : !=, and Right : 1."
    },
    "Expected out of dtypeFloat but found Int": {
      "answers": "dtype(out) == dtype({arg1_name})",
      "cot": "The error is due to the mismatch in the data types of the 'out' tensor and the expected output data type. The 'out' tensor is of type int32, but the function expects a float data type. Therefore, the data type of the 'out' tensor should be float. So, Left : out.dtype, Op : ==, Right : dtype(input)"
    },
    "Incompatible matrix sizes for triangular_solve: each A matrix is 8 by 8 but each b matrix is 7 by 2": {
      "answers": "{arg1_name}[-1] == {arg2_name}[-2]",
      "cot": "The error is triggered because incompatible matrix sizes with A and b. Let's see the what's args were.7,2 is the last two dimensions of b. in matrix calculation, last dimension of first matrix and first dimention of second matrix should be same, therefore, Left : A[-1], op : ==, right : b[-2]"
    },
    "Input 0 of layer \"max_pooling1d_20\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (0, 0)": {
      "answers": "len({arg_name}) == 3",
      "cot": "Error is caused because the input dimension to the layer \"max_pooling1d_20\" is not as expected. The layer expects an input with 3 dimensions but found input with 2 dimensions. Therefore, Left : len(inputs) which is the number of dimensions of inputs should be corrected. It says that cannot be 2, so Op : !=, and Right : 2. Also, it should be 3, so Op : ==, and Right : 3."
    },
    "Invalid reduction dimension 3 for input with 3 dimension(s) [Op:Mean] name: not defined": {
      "answers": "({arg2_name} < {arg1_name}.rank);(i< {arg1_name}.rank for i in {arg2_name})",
      "cot": "The error is due to an invalid reduction dimension. What the args were? The function is trying to reduce on dimension 3, but the input tensor only has 3 dimensions, indexed from 0. So, the maximum valid dimension for reduction would be 2. Therefore, Left : axis, which is the reduction dimension should be corrected. It says that cannot be 3 for input with 3 dimensions, so Op : !=, and Right : 3. Also, it should be less than 3, so Op : <, and Right : 3."
    },
    "Shapes of b and x, b and a are inconsistent: [4,9] vs. [7,2,7], [7,2,7] vs. [0,0]": {
      "answers": "len({arg1_name}) == len({arg2_name});len({arg1_name}) == len({arg3_name});all({arg1_name}.shape[i]=={arg3_name}.shape[i] for i in range({arg1_name}.rank));all({arg2_name}.shape[i]=={arg3_name}.shape[i] for i in range({arg2_name}.rank))",
      "cot": "The error is caused because the shapes of b and x, and x and a are inconsistent. Let's see what the args were. It seems shape of a, x, and b are not same. so, len(a), {arg_name}.shape, len(b), and b.shape should be corrected. It says should be same with b and x. so Op : ==, and Right : len(x), x.shape, len(b), and b.shape"
    },
    "The `pool_size` argument must be a tuple of 1 integers. Received: 0 including {0} that does not satisfy the requirement `> 0`.": {
      "answers": "pool_size > 0; all(p>0 for p in pool_size)",
      "cot": "The error indicates that the 'pool_size' argument is not satisfying the requirement of being a tuple of 1 integer which is greater than 0. The received 'pool_size' is 0, so it needs to be corrected. Therefore, Left: pool_size, Op: '>', and Right: 0."
    },
    "The size of tensor a (7) must match the size of tensor b (0) at non-singleton dimension 5": {
      "answers": "all({arg1_name}.shape[i] == {arg2_name}.shape[i] or {arg1_name}.shape[i] == 1 or {arg2_name}.shape[i] == 1 for i in range(-1, -min(len({arg1_name}.shape), len({arg2_name}.shape))-1, -1))",
      "cot": "Error is triggered because size of tensors at non-singleton dimension 5 doesn't match. What the args were? the two tensors matching problem at non-singleton dimension looks like broadcasting request. Broadcasting in tensor operations requires that the trailing dimensions of the tensors are either 1 or the same. We start from the last dimension because broadcasting aligns dimensions from the end. Therefore, we can revise the constraints as follows:"
    },
    "Input tensors must have 2 or fewer dimensions. Input 1 has 6 dimensions": {
      "answers": "all({arg}[i].dim < 2 for i in range(len({arg})))",
      "cot": "Error is triggered because size of tensors at non-singleton dimension 5 doesn't match. What the args were? the two tensors matching problem at non-singleton dimension looks like broadcasting request. Broadcasting in tensor operations requires that the trailing dimensions of the tensors are either 1 or the same. We start from the last dimension because broadcasting aligns dimensions from the end. Therefore, we can revise the constraints as follows:"
    },
    "Trying to resize storage that is not resizable": {
      "answers": "{arg1_name}.rank=={arg2_name}.rank and all({arg1_name}.shape[i]=={arg2_name}.shape[i] for i in range({arg1_name}.rank))",
      "cot": "Error is triggered because of we are trying to resize storageLet's see what the args were. I guess the storage indicates 'out' tensor. so, it means that 'out' tensor shape should be matched with the operation results. in this operation, the result shape is input.shape. Therefore, left : out.shape, out.rank op : == right : input.shape, input.rank"
    },
    "Value for attr ''T'' of float is not in the list of allowed values: half, int16, int32, int64, uint8, uint16, uint32, uint64": {
      "answers": "dtype(x) in [\"half\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\"] and dtype(y) in [\"half\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\"]",
      "cot": "Based on given values, the error arises because the attribute of 'x' and 'y' is a float, but it is expected to be one of int8, int16, int32, int64, uint8, uint16, uint32, uint64. The tensors ''x'' and ''y'' are both provided as float32, which is not compatible. So, the Left : dtype(x) or dtype(y) should be corrected to match one of the allowed types. Op : in, and Right : [int8, int16, int32, int64, uint8, uint16, uint32, uint64]."
    },
    "Value for attr ''mode'' of \"not defined\" is not in the list of allowed values:\"REFLECT\", \"SYMMETRIC\"": {
      "answers": "mode in [\"REFLECT\", \"SYMMETRIC\"] ",
      "cot": " The error is due to incorrect values for 'mode' from args . For 'mode', the value provided    \\ is 'not defined' which is not in the allowed values: \"REFLECT\", \"SYMMETRIC\"    . Therefore, dtype(mode) should be corrected to be either \"REFLECT\" or    \\ \"SYMMETRIC\", which is [\"SYMMETRIC\", \"REFLECT\"]. Op : in, and Right    \\ : [\"SYMMETRIC\", \"REFLECT\"]."
    },
    "cannot compute RightShift as input #1num_of_ex was expected to be a uint64 tensor but is a uint32 tensor [Op:RightShift] name: not defined": {
      "answers": "dtype(y)==dtype(x)",
      "cot": "Based on given valuesThe error arises because the function is trying to perform a operation on a uint64 tensor and a uint8 tensor. However, both tensors in generated args must have the same data type. Let's see what the args were. the 'x' tensor is uint64, but the 'y' tensor is of type uint8. Therefore, Left : dtype(y), which is the type of tensor y, should be corrected. It says that should be equal to the datatype of tensor x, so Op : ==, and Right : dtype(x)."
    },
    "dropout probability has to be between 0 and 1, but got 9.2818075": {
      "answers": "0<=p and p<=1",
      "cot": "The error is due to the invalid 'p' value. Let's see what the args were. It appears that 'p' is the dropout probability and it's currently 9.2818075, which is outside the valid range of 0 to 1. Therefore, 'p' should be corrected. It says it should fall between 0 and 1, so Operation : >= and <=; and Right : 0 and 1 respectively."
    },
    "expected padding to be a single integer value or a list of 3 values to match the convolution dimensions, but got padding=[]": {
      "answers": "len(padding) == input.rank;len(padding)==3",
      "cot": "Error is triggered because of wrong padding size Let's see what the args were. The input tensor rank is 3 and error message says 3. So, I guess length of padding size should be matched with input size. Therefore, left : len(padding) op : == right : input.rank, 3 "
    },
    "input have non-zero size for non-batch dimensions, but input has sizes [0, 0, 1, 0] with dimension 3 being empty": {
      "answers": "all({arg_name}[i]!=0 for i in range(1,len({arg_name}.shape)))",
      "cot": "Error is triggered because of zero size for non-batch dimensions, Let's see what the args were. There are zero on non-batch dimensions. Commonly, the first dimension is batch dimension. Therefore, Left : input[i], i in (1,len(input.shape)). op : !=, right : 0."
    },
    "mat1 and mat2 shapes cannot be multiplied (0x18 and 0x0)": {
      "answers": "in_features=={arg_name}[-1];out_features == {arg_name}[-1]",
      "cot": "Error is triggered because of unmatching shapes with (0x18 and 0x0). What the args were? it expects to have matching shapes maybe like (0*18 and 18*0). Let's see what the args were. It seems input has (0,0,2,26,18) shape, and out_features and in_features are 0. since we expect to have something like (0*18 and 18*0) from (0*18 and 0*0), one of arguments that had zero value should be corrected, which are in_features, or out_features. Therefore, Left : in_features or out_featurres. we expect Left(18*0) to match with (0*18). it seems the last value of input should be matched, which is input[-1], so Op : ==, Right : input[-1]."
    },
    "object of type 'int' has no len()": {
      "answers": "isinstance(window_shape, list);isinstance(strides, list)",
      "cot": "What the args were? Error is triggered because the 'int' of object don't have len(), which only list can have. So the type of object should be changed from 'int' to 'list'. Let's see what the args were. The type of 'strides' and 'window_shape' are 'int', but we don't know which one should be changed. Therefore, Left : dtype(strides) or dtype(window_shape). Op : == Right : list"
    },
    "required broadcastable shapes name:": {
      "answers": "all({arg_name1}.shape[i] == {arg_name2}.shape[i] or {arg_name1}.shape[i] == 1 or {arg_name2}.shape[i] == 1 for i in range(-1, -min(len({arg_name1}.shape), len({arg_name2}.shape))-1, -1))",
      "cot": "The error is due to the shapes of ''q'' and ''x'' not being broadcastable. What the args were? Broadcasting in tensor operations requires that the trailing dimensions of the tensors are either 1 or the same. So, the constraint should be that for each dimension starting from the last, the size of the dimension in ''q'' should be equal to the size of the dimension in ''x'' or one of them should be 1. We start from the last dimension because broadcasting aligns dimensions from the end. Therefore, we can revise the constraints as follows:"
    },
    "result type Double can't be cast to the desired output type Int ": {
      "answers": "dtype(input1)==dtype(input2);dtype(input2)==dtype(input3)",
      "cot": "The error is triggered because result type Double cannot be cast to the Int. Let's see the what's args were.the dtype of input1 and input2 is inconsistent, each for float64, int32. Therefore, the dtypes of two arguments should be consistent. Left : dtype(input1), op : ==, comparator : dtype(input2) or dtype(input3)"
    },
    "scale must be scalar: [8,2,6,6,8,1,7] [Op:AdjustSaturation] name:": {
      "answers": "scale.dim == 0",
      "cot": "The error is triggered because scale is not scalar. Let's see what the ars were. scale was the tensor of float32. To generate scalar, it should not have any dimension. However, scale had 7 dimensions. Therefore, the Left : scale.dim should be corrected to scalar float. Ops : '==', Right : 0."
    }
  }