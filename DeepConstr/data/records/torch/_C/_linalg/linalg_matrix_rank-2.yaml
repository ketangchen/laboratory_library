args:
  dtype:
  - Tensor
  - Optional[Tensor]
  - Optional[Tensor]
  - bool
  is_pos:
  - false
  - false
  - false
  - false
  name:
  - input
  - atol
  - rtol
  - hermitian
  required:
  - true
  - false
  - false
  - false
name: torch._C._linalg.linalg_matrix_rank
package: torch
pass_rate: 100
rules:
- - cot: 1) The input tensor should be of type float or double.
    length: 1
    target:
      choosen_dtype:
        atol: None
        hermitian: bool
        input: tensor
        rtol: None
      msg: This function doesn't handle types other than float and double
      package: torch
    txt: input.dtype in [torch.float32, torch.float64]
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        atol: None
        hermitian: bool
        input: tensor
        rtol: None
      msg: 'linalg.eigh: A must be batches of square matrices, but they are 7 by 1
        matrices'
      package: torch
    txt: all(input.shape[i] == input.shape[i+1] for i in range(input.ndim-2))
  - f1_score: 73.66482504604052
    overall_score: 48.83241252302026
    precision: 100.0
    recall: 58.309037900874635
- - cot: The error is due to negative dimensions in the input tensor. To prevent this
      error, the constraint should be that all dimensions in the input tensor must
      be non-negative.
    length: 1
    target:
      choosen_dtype:
        atol: tensor
        hermitian: bool
        input: tensor
        rtol: None
      msg: negative dimensions are not allowed
      package: torch
    txt: all(dim >= 0 for dim in input.shape)
  - f1_score: 83.50730688935283
    overall_score: 100
    precision: 100.0
    recall: 71.68458781362007
- - cot: 'Error is triggered because size of tensors at non-singleton dimension 4
      doesn''t match. What the args were? the two tensors matching problem at non-singleton
      dimension looks like broadcasting request. Broadcasting in tensor operations
      requires that the trailing dimensions of the tensors are either 1 or the same.
      We start from the last dimension because broadcasting aligns dimensions from
      the end. Therefore, we can revise the constraints as follows:'
    length: 1
    target:
      choosen_dtype:
        atol: tensor
        hermitian: bool
        input: tensor
        rtol: tensor
      msg: The size of tensor a (6) must match the size of tensor b (4) at non-singleton
        dimension 4
      package: torch
    txt: all(input.shape[i] == atol.shape[i] or input.shape[i] == 1 or atol.shape[i]
      == 1 for i in range(-1, -min(len(input.shape), len(atol.shape))-1, -1))
  - f1_score: 76.92307692307692
    overall_score: 50.46153846153846
    precision: 100.0
    recall: 62.5
- - cot: synthesized
    length: 3
    target:
      choosen_dtype:
        atol: tensor
        hermitian: bool
        input: tensor
        rtol: None
      msg: The size of tensor a (2) must match the size of tensor b (7) at non-singleton
        dimension 6
      package: torch
    txt: ((input.dim() == 7) or (input.dim() == atol.dim())) and (atol.shape[2] ==
      1)
  - f1_score: 66.893039049236
    overall_score: 45.446519524618
    precision: 98.5
    recall: 50.6426735218509
- - cot: synthesized
    length: 2
    target:
      choosen_dtype:
        atol: tensor
        hermitian: bool
        input: tensor
        rtol: tensor
      msg: The size of tensor a (7) must match the size of tensor b (6) at non-singleton
        dimension 5
      package: torch
    txt: (input.shape() == rtol.shape()) and (input.shape[2] == 2)
  - f1_score: 85.84070796460175
    overall_score: 54.920353982300874
    precision: 97.0
    recall: 76.98412698412697
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        atol: None
        hermitian: bool
        input: tensor
        rtol: None
      msg: 'linalg.eigh: A must be batches of square matrices, but they are 5 by 2
        matrices'
      package: torch
    txt: input.shape[-2] == input.shape[-1]
  - f1_score: 77.66990291262135
    overall_score: 50.83495145631068
    precision: 100.0
    recall: 63.49206349206349
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        atol: tensor
        hermitian: bool
        input: tensor
        rtol: None
      msg: 'torch.linalg.matrix_rank: The input tensor input must have at least 2
        dimensions.'
      package: torch
    txt: input.dim() >= 2
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: synthesized
    length: 2
    target:
      choosen_dtype:
        atol: None
        hermitian: bool
        input: tensor
        rtol: tensor
      msg: The size of tensor a (5) must match the size of tensor b (2) at non-singleton
        dimension 5
      package: torch
    txt: (input.dim == 7 and input.shape[6] == rtol.dim and input.shape[6] == rtol.shape[0])
      and (input.shape[6] == 1)
  - f1_score: 73.93715341959334
    overall_score: 100
    precision: 100.0
    recall: 58.65102639296187
- - cot: default
    length: 3
    target:
      choosen_dtype:
        atol: Optional[Tensor]
        hermitian: bool
        input: Tensor
        rtol: Optional[Tensor]
      msg: negative dimensions are not allowed
      package: torch
    txt: all(i >= 0 for i in input.shape) and all(i >= 0 for i in atol.shape) and
      all(i >= 0 for i in rtol.shape)
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
- - cot: default
    length: 3
    target:
      choosen_dtype:
        atol: Optional[Tensor]
        hermitian: bool
        input: Tensor
        rtol: Optional[Tensor]
      msg: Too large tensor shape
      package: torch
    txt: input.rank <= 7 and atol.rank <= 7 and rtol.rank <= 7
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
