args:
  dtype:
  - Tensor
  - List[int]
  - Optional[float]
  - Optional[float]
  is_pos:
  - true
  - false
  - false
  - false
  name:
  - self
  - output_size
  - scales_h
  - scales_w
  required:
  - true
  - true
  - false
  - false
name: torch._C._nn.upsample_nearest2d
package: torch
pass_rate: 96.97986577181209
rules:
- - cot: divided
    length: 1
    target:
      choosen_dtype:
        output_size: list[int]
        scales_h: None
        scales_w: None
        self: tensor
      msg: '''complex32'''
      package: torch
    txt: output_size[0] == self.size()[2]
  - f1_score: 66.66309123854106
    overall_score: 45.33154561927053
    precision: 97.6510067114094
    recall: 50.60457487829986
- - cot: 'The error is due to the fact that the function "upsample_nearest2d_channels_last"
      is not implemented for ''Bool'' dtype. To prevent this error, the dtype of the
      input tensor should be changed to a supported dtype for the "upsample_nearest2d_channels_last"
      function. Therefore, the condition to prevent this error would be:'
    length: 1
    target:
      choosen_dtype:
        output_size: list[int]
        scales_h: None
        scales_w: float
        self: tensor
      msg: '"upsample_nearest2d_channels_last" not implemented for ''Bool'''
      package: torch
    txt: self.dtype != torch.bool
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: 'The error is caused by the fact that the function `torch._C._nn.upsample_nearest2d`
      does not support the ''Long'' data type. Therefore, a constraint can be formulated
      to prevent the error as follows:'
    length: 1
    target:
      choosen_dtype:
        output_size: list[int]
        scales_h: None
        scales_w: float
        self: tensor
      msg: '"upsample_nearest2d_channels_last" not implemented for ''Long'''
      package: torch
    txt: self.dtype != "Long"
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: "Error is triggered because the input tensor is empty, meaning that it has\
      \ zero size for non-batch dimensions. To prevent this error, we can add a constraint\
      \ to check if the input tensor has non-zero size for non-batch dimensions. \n\
      \nThe constraint can be formulated as follows:"
    length: 1
    target:
      choosen_dtype:
        output_size: list[int]
        scales_h: None
        scales_w: float
        self: tensor
      msg: Non-empty 4D data tensor expected but got a tensor with sizes [0, 0, 1,
        1]
      package: torch
    txt: all(self.shape[i] != 0 for i in range(1, len(self.shape)))
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: divided
    length: 1
    target:
      choosen_dtype:
        output_size: list[int]
        scales_h: None
        scales_w: float
        self: tensor
      msg: 'Input and output sizes should be greater than 0, but got input (H: 1,
        W: 0) output (H: 1, W: 1)'
      package: torch
    txt: self.shape[3] > 0
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: synthesized
    length: 5
    target:
      choosen_dtype:
        output_size: list[int]
        scales_h: None
        scales_w: float
        self: tensor
      msg: '"upsample_nearest2d_channels_last" not implemented for ''Int'''
      package: torch
    txt: ((((output_size[0] == self.size(2) * scales_w) and (self.dtype != torch.int))
      or (dtype(self) == Float)) or (self.dtype != 'Int')) or (self.dtype != torch.int32)
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: divided
    length: 1
    target:
      choosen_dtype:
        output_size: list[int]
        scales_h: None
        scales_w: None
        self: tensor
      msg: 'Input and output sizes should be greater than 0, but got input (H: 8,
        W: 7) output (H: 8, W: -3)'
      package: torch
    txt: output_size[1] > 0
  - f1_score: 99.16805324459234
    overall_score: 61.58402662229617
    precision: 100.0
    recall: 98.34983498349835
- - cot: synthesized
    length: 2
    target:
      choosen_dtype:
        output_size: list[int]
        scales_h: float
        scales_w: float
        self: tensor
      msg: It is expected input_size equals to 4, but got size 3
      package: torch
    txt: (len(output_size) == 4) or (len(self.shape) == 4)
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: "Based on the given runtime information, the error is caused because the\
      \ size of the output_size list is not equal to 2. The error message indicates\
      \ that the expected size is 2, but the actual size is 4. To prevent this error,\
      \ we need to ensure that the length of the output_size list is always equal\
      \ to 2. \n\nThe constraint for the length of the output_size list can be expressed\
      \ as:"
    length: 1
    target:
      choosen_dtype:
        output_size: list[int]
        scales_h: None
        scales_w: float
        self: tensor
      msg: It is expected output_size equals to 2, but got size 4
      package: torch
    txt: len(output_size) == 2
  - f1_score: 91.88361408882082
    overall_score: 57.94180704441041
    precision: 100.0
    recall: 84.98583569405098
- - cot: default
    length: 1
    target:
      choosen_dtype:
        output_size: List[int]
        scales_h: Optional[float]
        scales_w: Optional[float]
        self: Tensor
      msg: negative dimensions are not allowed
      package: torch
    txt: all(i >= 0 for i in self.shape)
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
- - cot: default
    length: 1
    target:
      choosen_dtype:
        output_size: List[int]
        scales_h: Optional[float]
        scales_w: Optional[float]
        self: Tensor
      msg: Too large tensor shape
      package: torch
    txt: self.rank <= 7
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
