args:
  dtype:
  - Tensor
  - Tensor
  is_pos:
  - true
  - false
  name:
  - self
  - other
  required:
  - true
  - true
name: torch.lcm
package: torch
pass_rate: 100
rules:
- - cot: divided
    length: 1
    target:
      choosen_dtype:
        other: tensor
        self: tensor
      msg: The size of tensor a (7) must match the size of tensor b (8) at non-singleton
        dimension 5
      package: torch
    txt: other.shape[6] == 1
  - f1_score: 94.11764705882352
    overall_score: 100
    precision: 100.0
    recall: 88.88888888888889
- - cot: The error occurs because the function torch.lcm does not have an implementation
      for the 'Float' data type. Therefore, the constraint to prevent the error is
      to ensure that the data type of the input tensors is not 'Float'.
    length: 1
    target:
      choosen_dtype:
        other: tensor
        self: tensor
      msg: '"lcm_cpu" not implemented for ''Float'''
      package: torch
    txt: dtype(self) != "Float" and dtype(other) != "Float"
  - f1_score: 84.92569002123143
    overall_score: 100
    precision: 100.0
    recall: 73.80073800738008
- - cot: default
    length: 2
    target:
      choosen_dtype:
        other: Tensor
        self: Tensor
      msg: negative dimensions are not allowed
      package: torch
    txt: all(i >= 0 for i in self.shape) and all(i >= 0 for i in other.shape)
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
- - cot: default
    length: 2
    target:
      choosen_dtype:
        other: Tensor
        self: Tensor
      msg: Too large tensor shape
      package: torch
    txt: self.rank <= 7 and other.rank <= 7
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
