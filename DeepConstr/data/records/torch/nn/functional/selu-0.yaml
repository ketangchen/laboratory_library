args:
  dtype:
  - Tensor
  - bool
  is_pos:
  - false
  - false
  name:
  - input
  - inplace
  required:
  - true
  - false
name: torch.nn.functional.selu
package: torch
pass_rate: 96.0
rules:
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        inplace: bool
        input: tensor
      msg: '''complex32'''
      package: torch
    txt: input.dim() == 2
  - f1_score: 65.83427922814982
    overall_score: 44.91713961407491
    precision: 96.66666666666667
    recall: 49.91394148020654
- - cot: 'The error is due to the fact that the input tensor has a data type of ''Bool'',
      which is not supported by the SELU function. To prevent this error, the input
      tensor should have a data type other than ''Bool''. Therefore, the constraint
      should be:'
    length: 1
    target:
      choosen_dtype:
        inplace: bool
        input: tensor
      msg: '"elu_cpu" not implemented for ''Bool'''
      package: torch
    txt: input.dtype != torch.bool
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: Based on the given runtime information, the error is due to the input tensor
      having a data type of 'Long' which is not supported by the SELU activation function.
      Therefore, the constraint to prevent this error is to ensure that the data type
      of the input tensor is not 'Long'.
    length: 1
    target:
      choosen_dtype:
        inplace: bool
        input: tensor
      msg: '"elu_cpu" not implemented for ''Long'''
      package: torch
    txt: input.dtype != torch.int64
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: The error is due to the input tensor having a data type of 'Int', which is
      not supported by the 'selu' operation. To prevent the error, the input tensor
      should have a data type other than 'Int' that is supported by the 'selu' operation.
    length: 1
    target:
      choosen_dtype:
        inplace: bool
        input: tensor
      msg: '"elu_cpu" not implemented for ''Int'''
      package: torch
    txt: input.dtype != torch.int
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: default
    length: 1
    target:
      choosen_dtype:
        inplace: bool
        input: Tensor
      msg: negative dimensions are not allowed
      package: torch
    txt: all(i >= 0 for i in input.shape)
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
- - cot: default
    length: 1
    target:
      choosen_dtype:
        inplace: bool
        input: Tensor
      msg: Too large tensor shape
      package: torch
    txt: input.rank <= 7
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
