args:
  dtype:
  - Tensor
  - int
  - Tensor
  is_pos:
  - true
  - false
  - false
  name:
  - self
  - dim
  - out
  required:
  - true
  - true
  - true
name: torch.logcumsumexp
package: torch
pass_rate: 98.49246231155779
rules:
- - cot: divided
    length: 1
    target:
      choosen_dtype:
        dim: int
        out: tensor
        self: tensor
      msg: Dimension out of range (expected to be in range of [-2, 1], but got 13)
      package: torch
    txt: dim >= -len(self.shape)
  - f1_score: 78.1316348195329
    overall_score: 49.0
    precision: 92.0
    recall: 67.89667896678966
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        dim: int
        out: tensor
        self: tensor
      msg: Trying to resize storage that is not resizable
      package: torch
    txt: out.rank==self.rank and all(out.shape[i]==self.shape[i] for i in range(out.rank))
  - f1_score: 73.12614259597805
    overall_score: 100
    precision: 100.0
    recall: 57.636887608069166
- - cot: 'Based on given values, Error is triggered because the ''dim'' parameter
      in the torch.logcumsumexp function is expected to be within the range of the
      tensor''s dimensions. Let''s see what the args were. It seems ''dim'' is 0 and
      the tensor''s dimension is also 0, which is not valid. Therefore, the ''dim''
      parameter should be less than the tensor''s dimension.


      The constraint that prevents the error can be formulated as follows:'
    length: 1
    target:
      choosen_dtype:
        dim: int
        out: tensor
        self: tensor
      msg: '''complex32'''
      package: torch
    txt: 0 <= dim < self.dim()
  - f1_score: 65.6140350877193
    overall_score: 44.80701754385965
    precision: 93.5
    recall: 50.54054054054055
- - cot: synthesized
    length: 2
    target:
      choosen_dtype:
        dim: int
        out: tensor
        self: tensor
      msg: '"logcumsumexp_out_cpu" not implemented for ''Bool'''
      package: torch
    txt: (self.dtype != torch.bool) and (out.dtype != torch.bool)
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: "The error is due to the mismatch in the data types of the 'out' tensor and\
      \ the expected output data type. The 'out' tensor is of type int32, but the\
      \ function expects a float data type. Therefore, the data type of the 'out'\
      \ tensor should be float. \n\nThe formula to prevent the error is:"
    length: 1
    target:
      choosen_dtype:
        dim: int
        out: tensor
        self: tensor
      msg: '"logcumsumexp_out_cpu" not implemented for ''Int'''
      package: torch
    txt: dtype(out) == float32
  - f1_score: 97.08737864077668
    overall_score: 60.54368932038834
    precision: 100.0
    recall: 94.33962264150942
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        dim: int
        out: tensor
        self: tensor
      msg: expected scalar_type Float but found Int
      package: torch
    txt: dtype(out) == dtype(self)
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: default
    length: 2
    target:
      choosen_dtype:
        dim: int
        out: Tensor
        self: Tensor
      msg: negative dimensions are not allowed
      package: torch
    txt: all(i >= 0 for i in self.shape) and all(i >= 0 for i in out.shape)
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
- - cot: default
    length: 2
    target:
      choosen_dtype:
        dim: int
        out: Tensor
        self: Tensor
      msg: Too large tensor shape
      package: torch
    txt: self.rank <= 7 and out.rank <= 7
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
