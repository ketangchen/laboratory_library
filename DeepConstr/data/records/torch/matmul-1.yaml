args:
  dtype:
  - Tensor
  - Tensor
  - Tensor
  is_pos:
  - true
  - false
  - false
  name:
  - self
  - other
  - out
  required:
  - true
  - true
  - true
name: torch.matmul
package: torch
pass_rate: 36.0
rules:
- - cot: 'Error is triggered because size of tensors at non-singleton dimension 2
      doesn''t match. What the args were? The two tensors matching problem at non-singleton
      dimension looks like broadcasting request. Broadcasting in tensor operations
      requires that the trailing dimensions of the tensors are either 1 or the same.
      We start from the last dimension because broadcasting aligns dimensions from
      the end. Therefore, we can revise the constraints as follows:'
    length: 1
    target:
      choosen_dtype:
        other: tensor
        out: tensor
        self: tensor
      msg: The size of tensor a (9) must match the size of tensor b (7) at non-singleton
        dimension 3
      package: torch
    txt: self.shape[-1] == other.shape[-1] or self.shape[-1] == 1 or other.shape[-1]
      == 1
  - f1_score: 76.48183556405354
    overall_score: 100
    precision: 100.0
    recall: 61.91950464396285
- - cot: "Based on the given runtime information, the error is due to the fact that\
      \ both arguments to matmul need to be at least 1D, but they are 0D and 7D respectively.\
      \ \n\nTo prevent this error, the self tensor should be at least 1D and the other\
      \ tensor should be at least 1D. \n\nSo the constraint to prevent the error is:"
    length: 1
    target:
      choosen_dtype:
        other: tensor
        out: tensor
        self: tensor
      msg: both arguments to matmul need to be at least 1D, but they are 0D and 7D
      package: torch
    txt: self.dim() >= 1 and other.dim() >= 1
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: "Error is triggered because the size of tensors at non-singleton dimension\
      \ 2 doesn't match. The shape of tensor a at non-singleton dimension 2 is 8,\
      \ while the shape of tensor b at non-singleton dimension 2 is 9. To prevent\
      \ this error, the size of tensor a at dimension 2 should match the size of tensor\
      \ b at dimension 2. \n\nTherefore, the constraint can be formulated as:"
    length: 1
    target:
      choosen_dtype:
        other: tensor
        out: tensor
        self: tensor
      msg: The size of tensor a (5) must match the size of tensor b (9) at non-singleton
        dimension 4
      package: torch
    txt: self.shape[2] == other.shape[2]
  - f1_score: 76.48183556405354
    overall_score: 100
    precision: 100.0
    recall: 61.91950464396285
- - cot: synthesized
    length: 2
    target:
      choosen_dtype:
        other: tensor
        out: tensor
        self: tensor
      msg: Trying to resize storage that is not resizable
      package: torch
    txt: (out.rank==self.rank) and (out.rank==other.rank)
  - f1_score: 77.16535433070867
    overall_score: 50.5
    precision: 98.0
    recall: 63.63636363636363
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        other: tensor
        out: tensor
        self: tensor
      msg: 'dot : expected both vectors to have same dtype, but found Int and Float'
      package: torch
    txt: dtype(self) == dtype(other)
  - f1_score: 99.25558312655089
    overall_score: 61.627791563275444
    precision: 100.0
    recall: 98.52216748768474
- - cot: "Based on the given runtime information, the error occurs because the result\
      \ dtype Float does not match the input dtype Int. The input tensors 'self' and\
      \ 'other' have dtype Int, but the output tensor 'out' has dtype Float. To prevent\
      \ this error, the dtypes of input and output tensors should be consistent. \n\
      \nWrap the final formula with"
    length: 1
    target:
      choosen_dtype:
        other: tensor
        out: tensor
        self: tensor
      msg: result dtype Float does not match input dtype Int
      package: torch
    txt: dtype(other) == dtype(out)
  - f1_score: 99.75062344139653
    overall_score: 61.875311720698264
    precision: 100.0
    recall: 99.50248756218907
- - cot: The error occurs because the shapes of the tensors cannot be multiplied together.
      In matrix multiplication, the number of columns in the first matrix must be
      equal to the number of rows in the second matrix. Here, the self tensor has
      9 columns and the other tensor has 1 row, which is not possible to multiply.
      Let's see what the args were. It seems the issue is with the self and other
      tensors. Therefore, the column of the self tensor and the row of the other tensor
      should be the same. The last dimension of self tensor is self.shape[-1] and
      the second last dimension of other tensor is other.shape[-2]. So, the condition
      to prevent this error is self.shape[-1] == other.shape[-2].
    length: 1
    target:
      choosen_dtype:
        other: tensor
        out: tensor
        self: tensor
      msg: mat1 and mat2 shapes cannot be multiplied (9x1 and 9x8)
      package: torch
    txt: self.shape[-1] == other.shape[-2]
  - f1_score: 84.21052631578947
    overall_score: 54.10526315789473
    precision: 100.0
    recall: 72.72727272727273
- - cot: default
    length: 3
    target:
      choosen_dtype:
        other: Tensor
        out: Tensor
        self: Tensor
      msg: negative dimensions are not allowed
      package: torch
    txt: all(i >= 0 for i in self.shape) and all(i >= 0 for i in other.shape) and
      all(i >= 0 for i in out.shape)
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
- - cot: default
    length: 3
    target:
      choosen_dtype:
        other: Tensor
        out: Tensor
        self: Tensor
      msg: Too large tensor shape
      package: torch
    txt: self.rank <= 7 and other.rank <= 7 and out.rank <= 7
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
