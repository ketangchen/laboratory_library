args:
  dtype:
  - Tensor
  - Optional[Tensor]
  - Optional[Tensor]
  - bool
  is_pos:
  - false
  - false
  - false
  - false
  name:
  - input
  - atol
  - rtol
  - hermitian
  required:
  - true
  - false
  - false
  - false
name: torch._C._linalg.linalg_matrix_rank
package: torch
pass_rate: 100
rules:
- - cot: synthesized
    length: 2
    target:
      choosen_dtype:
        atol: None
        hermitian: bool
        input: tensor
        rtol: tensor
      msg: The size of tensor a (5) must match the size of tensor b (2) at non-singleton
        dimension 5
      package: torch
    txt: (input.dim == 7 and input.shape[6] == rtol.dim and input.shape[6] == rtol.shape[0])
      and (input.shape[6] == 1)
  - f1_score: 73.93715341959334
    overall_score: 100
    precision: 100.0
    recall: 58.65102639296187
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        atol: tensor
        hermitian: bool
        input: tensor
        rtol: None
      msg: 'torch.linalg.matrix_rank: The input tensor input must have at least 2
        dimensions.'
      package: torch
    txt: input.dim() >= 2
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        atol: None
        hermitian: bool
        input: tensor
        rtol: None
      msg: 'linalg.eigh: A must be batches of square matrices, but they are 5 by 2
        matrices'
      package: torch
    txt: input.shape[-2] == input.shape[-1]
  - f1_score: 66.3265306122449
    overall_score: 51.75
    precision: 97.5
    recall: 50.25773195876289
- - cot: synthesized
    length: 2
    target:
      choosen_dtype:
        atol: tensor
        hermitian: bool
        input: tensor
        rtol: tensor
      msg: The size of tensor a (7) must match the size of tensor b (6) at non-singleton
        dimension 5
      package: torch
    txt: (input.shape() == rtol.shape()) and (input.shape[2] == 2)
  - f1_score: 70.3030303030303
    overall_score: 45.0
    precision: 87.0
    recall: 58.98305084745762
- - cot: synthesized
    length: 3
    target:
      choosen_dtype:
        atol: tensor
        hermitian: bool
        input: tensor
        rtol: None
      msg: The size of tensor a (2) must match the size of tensor b (7) at non-singleton
        dimension 6
      package: torch
    txt: ((input.dim() == 7) or (input.dim() == atol.dim())) and (atol.shape[2] ==
      1)
  - f1_score: 69.44444444444444
    overall_score: 100
    precision: 100.0
    recall: 53.191489361702125
- - cot: 'Error is triggered because size of tensors at non-singleton dimension 4
      doesn''t match. What the args were? the two tensors matching problem at non-singleton
      dimension looks like broadcasting request. Broadcasting in tensor operations
      requires that the trailing dimensions of the tensors are either 1 or the same.
      We start from the last dimension because broadcasting aligns dimensions from
      the end. Therefore, we can revise the constraints as follows:'
    length: 1
    target:
      choosen_dtype:
        atol: tensor
        hermitian: bool
        input: tensor
        rtol: tensor
      msg: The size of tensor a (6) must match the size of tensor b (4) at non-singleton
        dimension 4
      package: torch
    txt: all(input.shape[i] == atol.shape[i] or input.shape[i] == 1 or atol.shape[i]
      == 1 for i in range(-1, -min(len(input.shape), len(atol.shape))-1, -1))
  - f1_score: 83.54430379746834
    overall_score: 52.5
    precision: 99.0
    recall: 72.26277372262773
- - cot: The error is due to negative dimensions in the input tensor. To prevent this
      error, the constraint should be that all dimensions in the input tensor must
      be non-negative.
    length: 1
    target:
      choosen_dtype:
        atol: tensor
        hermitian: bool
        input: tensor
        rtol: None
      msg: negative dimensions are not allowed
      package: torch
    txt: all(dim >= 0 for dim in input.shape)
  - f1_score: 83.50730688935283
    overall_score: 100
    precision: 100.0
    recall: 71.68458781362007
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        atol: None
        hermitian: bool
        input: tensor
        rtol: None
      msg: 'linalg.eigh: A must be batches of square matrices, but they are 7 by 1
        matrices'
      package: torch
    txt: all(input.shape[i] == input.shape[i+1] for i in range(input.ndim-2))
  - f1_score: 71.55635062611806
    overall_score: 100
    precision: 100.0
    recall: 55.71030640668524
- - cot: 1) The input tensor should be of type float or double.
    length: 1
    target:
      choosen_dtype:
        atol: None
        hermitian: bool
        input: tensor
        rtol: None
      msg: This function doesn't handle types other than float and double
      package: torch
    txt: input.dtype in [torch.float32, torch.float64]
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: default
    length: 3
    target:
      choosen_dtype:
        atol: Optional[Tensor]
        hermitian: bool
        input: Tensor
        rtol: Optional[Tensor]
      msg: negative dimensions are not allowed
      package: torch
    txt: all(i >= 0 for i in input.shape) and all(i >= 0 for i in atol.shape) and
      all(i >= 0 for i in rtol.shape)
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
- - cot: default
    length: 3
    target:
      choosen_dtype:
        atol: Optional[Tensor]
        hermitian: bool
        input: Tensor
        rtol: Optional[Tensor]
      msg: Too large tensor shape
      package: torch
    txt: input.rank <= 7 and atol.rank <= 7 and rtol.rank <= 7
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
