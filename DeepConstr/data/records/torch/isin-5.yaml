args:
  dtype:
  - number
  - Tensor
  - bool
  - bool
  - Tensor
  is_pos:
  - false
  - false
  - false
  - false
  - false
  name:
  - element
  - test_elements
  - assume_unique
  - invert
  - out
  required:
  - true
  - true
  - false
  - false
  - true
name: torch.isin
package: torch
pass_rate: 99.0
rules:
- - cot: 'The error is due to the mismatch in the data types of the ''out'' tensor
      and the expected output data type. The ''out'' tensor is of type int, but the
      function expects a bool data type. Therefore, the data type of the ''out'' tensor
      should be bool. So, the constraint to prevent this error can be formulated as:'
    length: 1
    target:
      choosen_dtype:
        assume_unique: bool
        element: int
        invert: bool
        out: tensor
        test_elements: tensor
      msg: Expected out tensor to have dtype bool, but got float instead
      package: torch
    txt: dtype(out) == bool
  - f1_score: 100.0
    overall_score: 100
    precision: 100.0
    recall: 100.0
- - cot: divided
    length: 1
    target:
      choosen_dtype:
        assume_unique: bool
        element: int
        invert: bool
        out: tensor
        test_elements: tensor
      msg: Trying to resize storage that is not resizable
      package: torch
    txt: out.shape[0]==0
  - f1_score: 66.815144766147
    overall_score: 100
    precision: 100.0
    recall: 50.16722408026756
- - cot: default
    length: 2
    target:
      choosen_dtype:
        assume_unique: bool
        element: number
        invert: bool
        out: Tensor
        test_elements: Tensor
      msg: negative dimensions are not allowed
      package: torch
    txt: all(i >= 0 for i in test_elements.shape) and all(i >= 0 for i in out.shape)
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
- - cot: default
    length: 2
    target:
      choosen_dtype:
        assume_unique: bool
        element: number
        invert: bool
        out: Tensor
        test_elements: Tensor
      msg: Too large tensor shape
      package: torch
    txt: test_elements.rank <= 7 and out.rank <= 7
  - f1_score: -1
    overall_score: -1
    precision: -1
    recall: -1
